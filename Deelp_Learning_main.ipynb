{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b857736",
   "metadata": {},
   "source": [
    "# OCTDL Eye Disease Classification\n",
    "**Deep Learning Model Comparison: ResNet50 vs InceptionV3**\n",
    "\n",
    "Advanced Machine Learning Final Project | June 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578f8156",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffdebab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import os, shutil, random, json, pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# TensorFlow & Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, callbacks, optimizers\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.applications import ResNet50, InceptionV3\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocess\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input as inception_preprocess\n",
    "\n",
    "# Configuration\n",
    "tf.random.set_seed(123)\n",
    "print(f\"TensorFlow: {tf.__version__}\")\n",
    "print(f\"GPU Available: {len(tf.config.list_physical_devices('GPU')) > 0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e866dfc",
   "metadata": {},
   "source": [
    "## 2. Configuration & Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3deebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project configuration\n",
    "PROJECT_DIR = r'c:\\Users\\Mr Computer\\Desktop\\Folders\\CAP\\S#3\\T#2\\Advance Machine Learning\\Final_Project'\n",
    "BASE_DATA_DIR = os.path.join(PROJECT_DIR, 'archive', 'OCTDL', 'OCTDL')\n",
    "\n",
    "# Training parameters\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "SEED = 123\n",
    "INITIAL_EPOCHS = 15\n",
    "FINE_TUNE_EPOCHS = 15\n",
    "\n",
    "# Data directories\n",
    "TRAIN_DIR = os.path.join(PROJECT_DIR, 'train_data')\n",
    "VAL_DIR = os.path.join(PROJECT_DIR, 'val_data')\n",
    "TEST_DIR = os.path.join(PROJECT_DIR, 'test_data')\n",
    "\n",
    "print(f\"Base data directory: {BASE_DATA_DIR}\")\n",
    "print(f\"Data exists: {os.path.exists(BASE_DATA_DIR)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337f3941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/val/test splits\n",
    "def create_data_splits():\n",
    "    # Remove existing splits\n",
    "    for folder in [TRAIN_DIR, VAL_DIR, TEST_DIR]:\n",
    "        if os.path.exists(folder):\n",
    "            shutil.rmtree(folder)\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "    \n",
    "    # Split function\n",
    "    def split_class_data(src_dir, dest_dirs, ratios=[0.8, 0.1, 0.1]):\n",
    "        for class_name in os.listdir(src_dir):\n",
    "            class_path = os.path.join(src_dir, class_name)\n",
    "            if not os.path.isdir(class_path):\n",
    "                continue\n",
    "            \n",
    "            images = [f for f in os.listdir(class_path) if f.lower().endswith(('.jpg', '.png', '.jpeg', '.tiff'))]\n",
    "            random.seed(SEED)\n",
    "            random.shuffle(images)\n",
    "            \n",
    "            total = len(images)\n",
    "            if total == 0:\n",
    "                continue\n",
    "            \n",
    "            # Calculate splits\n",
    "            train_end = int(total * ratios[0])\n",
    "            val_end = int(total * (ratios[0] + ratios[1]))\n",
    "            \n",
    "            splits = {\n",
    "                dest_dirs[0]: images[:train_end],\n",
    "                dest_dirs[1]: images[train_end:val_end],\n",
    "                dest_dirs[2]: images[val_end:]\n",
    "            }\n",
    "            \n",
    "            # Copy files\n",
    "            for dest_dir, file_list in splits.items():\n",
    "                class_dest = os.path.join(dest_dir, class_name)\n",
    "                os.makedirs(class_dest, exist_ok=True)\n",
    "                \n",
    "                for fname in file_list:\n",
    "                    src_file = os.path.join(class_path, fname)\n",
    "                    dst_file = os.path.join(class_dest, fname)\n",
    "                    shutil.copy2(src_file, dst_file)\n",
    "    \n",
    "    # Create splits\n",
    "    split_class_data(BASE_DATA_DIR, [TRAIN_DIR, VAL_DIR, TEST_DIR])\n",
    "    \n",
    "    # Count images\n",
    "    def count_images(directory):\n",
    "        count = 0\n",
    "        for root, dirs, files in os.walk(directory):\n",
    "            count += len([f for f in files if f.lower().endswith(('.jpg', '.png', '.jpeg', '.tiff'))])\n",
    "        return count\n",
    "    \n",
    "    train_count = count_images(TRAIN_DIR)\n",
    "    val_count = count_images(VAL_DIR)\n",
    "    test_count = count_images(TEST_DIR)\n",
    "    \n",
    "    print(f\"Train: {train_count}, Val: {val_count}, Test: {test_count}\")\n",
    "    return train_count > 0\n",
    "\n",
    "# Create data splits\n",
    "data_ready = create_data_splits()\n",
    "print(f\"Data preparation: {'‚úÖ Success' if data_ready else '‚ùå Failed'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41c4618",
   "metadata": {},
   "source": [
    "## 3. Data Loading & Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c439cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_ds = image_dataset_from_directory(\n",
    "    TRAIN_DIR, labels='inferred', label_mode='categorical',\n",
    "    batch_size=BATCH_SIZE, image_size=IMG_SIZE, shuffle=True, seed=SEED\n",
    ")\n",
    "\n",
    "val_ds = image_dataset_from_directory(\n",
    "    VAL_DIR, labels='inferred', label_mode='categorical',\n",
    "    batch_size=BATCH_SIZE, image_size=IMG_SIZE, shuffle=False\n",
    ")\n",
    "\n",
    "test_ds = image_dataset_from_directory(\n",
    "    TEST_DIR, labels='inferred', label_mode='categorical',\n",
    "    batch_size=BATCH_SIZE, image_size=IMG_SIZE, shuffle=False\n",
    ")\n",
    "\n",
    "# Get class names and optimize datasets\n",
    "class_names = train_ds.class_names\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.prefetch(AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(AUTOTUNE)\n",
    "test_ds = test_ds.prefetch(AUTOTUNE)\n",
    "\n",
    "print(f\"Classes: {class_names}\")\n",
    "print(f\"Number of classes: {len(class_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa32ea04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation for medical images\n",
    "data_augmentation = keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.15, fill_mode='constant', fill_value=0.0),\n",
    "    layers.RandomZoom(0.15, fill_mode='constant', fill_value=0.0),\n",
    "    layers.RandomTranslation(0.1, 0.1, fill_mode='constant', fill_value=0.0),\n",
    "    layers.RandomContrast(0.2),\n",
    "    layers.RandomBrightness(0.15),\n",
    "    layers.GaussianNoise(0.01),\n",
    "], name=\"data_augmentation\")\n",
    "\n",
    "# Calculate class weights for imbalanced data\n",
    "def calculate_class_weights(dataset, class_names):\n",
    "    class_counts = {name: 0 for name in class_names}\n",
    "    \n",
    "    for images, labels in dataset:\n",
    "        for label in labels:\n",
    "            class_idx = tf.argmax(label).numpy()\n",
    "            class_counts[class_names[class_idx]] += 1\n",
    "    \n",
    "    total_samples = sum(class_counts.values())\n",
    "    class_weights = {}\n",
    "    \n",
    "    for i, class_name in enumerate(class_names):\n",
    "        class_weights[i] = total_samples / (len(class_names) * class_counts[class_name])\n",
    "    \n",
    "    return class_weights, class_counts\n",
    "\n",
    "class_weights, train_class_counts = calculate_class_weights(train_ds, class_names)\n",
    "\n",
    "print(\"Class distribution:\")\n",
    "for name, count in train_class_counts.items():\n",
    "    print(f\"  {name}: {count}\")\n",
    "\n",
    "print(\"\\nClass weights:\")\n",
    "for i, weight in class_weights.items():\n",
    "    print(f\"  {class_names[i]}: {weight:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adecd8c",
   "metadata": {},
   "source": [
    "## 4. Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326fa0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model creation function\n",
    "def create_model(architecture='resnet50', num_classes=None, input_shape=None):\n",
    "    if num_classes is None:\n",
    "        num_classes = len(class_names)\n",
    "    if input_shape is None:\n",
    "        input_shape = IMG_SIZE + (3,)\n",
    "    \n",
    "    # Load base model\n",
    "    if architecture.lower() == 'resnet50':\n",
    "        base_model = ResNet50(weights=\"imagenet\", include_top=False, input_shape=input_shape)\n",
    "        preprocessing_func = resnet_preprocess\n",
    "        model_name = \"ResNet50_OCT_Classifier\"\n",
    "    elif architecture.lower() == 'inceptionv3':\n",
    "        base_model = InceptionV3(weights=\"imagenet\", include_top=False, input_shape=input_shape)\n",
    "        preprocessing_func = inception_preprocess\n",
    "        model_name = \"InceptionV3_OCT_Classifier\"\n",
    "    else:\n",
    "        raise ValueError(\"Architecture must be 'resnet50' or 'inceptionv3'\")\n",
    "    \n",
    "    # Freeze base model\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Build model\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = preprocessing_func(inputs)\n",
    "    x = data_augmentation(x)\n",
    "    x = base_model(x, training=False)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=model_name)\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=1e-4),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\", keras.metrics.Precision(), keras.metrics.Recall(), keras.metrics.F1Score()]\n",
    "    )\n",
    "    \n",
    "    return model, base_model\n",
    "\n",
    "# Create both models\n",
    "print(\"Creating models...\")\n",
    "resnet_model, resnet_base = create_model('resnet50')\n",
    "inception_model, inception_base = create_model('inceptionv3')\n",
    "\n",
    "print(f\"ResNet50 parameters: {resnet_model.count_params():,}\")\n",
    "print(f\"InceptionV3 parameters: {inception_model.count_params():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e37155",
   "metadata": {},
   "source": [
    "## 5. Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79269839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create callbacks\n",
    "def create_callbacks(model_name, project_dir):\n",
    "    checkpoint_path = os.path.join(project_dir, f\"best_model_{model_name.lower()}.keras\")\n",
    "    \n",
    "    callbacks_list = [\n",
    "        callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True, verbose=1),\n",
    "        callbacks.ModelCheckpoint(filepath=checkpoint_path, monitor=\"val_accuracy\", save_best_only=True, verbose=1),\n",
    "        callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.2, patience=3, min_lr=1e-6, verbose=1),\n",
    "        callbacks.TensorBoard(log_dir=os.path.join(project_dir, \"logs\", model_name.lower()), histogram_freq=1)\n",
    "    ]\n",
    "    \n",
    "    return callbacks_list, checkpoint_path\n",
    "\n",
    "# Create callbacks for both models\n",
    "resnet_callbacks, resnet_checkpoint = create_callbacks(\"ResNet50\", PROJECT_DIR)\n",
    "inception_callbacks, inception_checkpoint = create_callbacks(\"InceptionV3\", PROJECT_DIR)\n",
    "\n",
    "print(\"Training callbacks configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13759b0",
   "metadata": {},
   "source": [
    "## 6. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d868b8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_model(model, base_model, model_name, callbacks_list, train_dataset, val_dataset, class_weights):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Training {model_name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Phase 1: Frozen backbone\n",
    "    print(f\"\\nPhase 1: Initial training ({INITIAL_EPOCHS} epochs)\")\n",
    "    history_initial = model.fit(\n",
    "        train_dataset, epochs=INITIAL_EPOCHS, validation_data=val_dataset,\n",
    "        callbacks=callbacks_list, class_weight=class_weights, verbose=1\n",
    "    )\n",
    "    \n",
    "    # Phase 2: Fine-tuning\n",
    "    print(f\"\\nPhase 2: Fine-tuning ({FINE_TUNE_EPOCHS} epochs)\")\n",
    "    base_model.trainable = True\n",
    "    \n",
    "    # Unfreeze top layers\n",
    "    if model_name.lower().startswith('resnet'):\n",
    "        for layer in base_model.layers[:-10]:\n",
    "            layer.trainable = False\n",
    "    else:  # InceptionV3\n",
    "        for layer in base_model.layers[:-20]:\n",
    "            layer.trainable = False\n",
    "    \n",
    "    # Recompile with lower learning rate\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=1e-5),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\", keras.metrics.Precision(), keras.metrics.Recall(), keras.metrics.F1Score()]\n",
    "    )\n",
    "    \n",
    "    total_epochs = INITIAL_EPOCHS + FINE_TUNE_EPOCHS\n",
    "    history_finetune = model.fit(\n",
    "        train_dataset, epochs=total_epochs, initial_epoch=INITIAL_EPOCHS,\n",
    "        validation_data=val_dataset, callbacks=callbacks_list,\n",
    "        class_weight=class_weights, verbose=1\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n{model_name} training completed!\")\n",
    "    \n",
    "    return {\n",
    "        'initial_history': history_initial,\n",
    "        'finetune_history': history_finetune,\n",
    "        'model': model,\n",
    "        'model_name': model_name\n",
    "    }\n",
    "\n",
    "# Train both models\n",
    "print(\"Starting model training...\")\n",
    "\n",
    "resnet_results = train_model(\n",
    "    resnet_model, resnet_base, \"ResNet50\", resnet_callbacks, train_ds, val_ds, class_weights\n",
    ")\n",
    "\n",
    "inception_results = train_model(\n",
    "    inception_model, inception_base, \"InceptionV3\", inception_callbacks, train_ds, val_ds, class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54817862",
   "metadata": {},
   "source": [
    "## 7. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fda1d3e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'resnet_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 44\u001b[39m\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m     33\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mresnet_metrics\u001b[39m\u001b[33m'\u001b[39m: resnet_metrics,\n\u001b[32m     34\u001b[39m         \u001b[33m'\u001b[39m\u001b[33minception_metrics\u001b[39m\u001b[33m'\u001b[39m: inception_metrics,\n\u001b[32m   (...)\u001b[39m\u001b[32m     40\u001b[39m         \u001b[33m'\u001b[39m\u001b[33my_true_classes\u001b[39m\u001b[33m'\u001b[39m: y_true_classes\n\u001b[32m     41\u001b[39m     }\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# Evaluate models\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m eval_results = evaluate_models(\u001b[43mresnet_model\u001b[49m, inception_model, test_ds, class_names)\n",
      "\u001b[31mNameError\u001b[39m: name 'resnet_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Comprehensive model evaluation\n",
    "def evaluate_models(resnet_model, inception_model, test_dataset, class_names):\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"MODEL EVALUATION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Evaluate models\n",
    "    print(\"\\nEvaluating ResNet50...\")\n",
    "    resnet_results = resnet_model.evaluate(test_dataset, verbose=1)\n",
    "    resnet_metrics = dict(zip(resnet_model.metrics_names, resnet_results))\n",
    "    \n",
    "    print(\"\\nEvaluating InceptionV3...\")\n",
    "    inception_results = inception_model.evaluate(test_dataset, verbose=1)\n",
    "    inception_metrics = dict(zip(inception_model.metrics_names, inception_results))\n",
    "    \n",
    "    # Generate predictions\n",
    "    print(\"\\nGenerating predictions...\")\n",
    "    resnet_predictions = resnet_model.predict(test_dataset, verbose=1)\n",
    "    inception_predictions = inception_model.predict(test_dataset, verbose=1)\n",
    "    \n",
    "    # Get true labels\n",
    "    y_true = []\n",
    "    for _, labels in test_dataset:\n",
    "        y_true.extend(labels.numpy())\n",
    "    y_true = np.array(y_true)\n",
    "    \n",
    "    # Convert to class indices\n",
    "    resnet_pred_classes = np.argmax(resnet_predictions, axis=1)\n",
    "    inception_pred_classes = np.argmax(inception_predictions, axis=1)\n",
    "    y_true_classes = np.argmax(y_true, axis=1)\n",
    "    \n",
    "    return {\n",
    "        'resnet_metrics': resnet_metrics,\n",
    "        'inception_metrics': inception_metrics,\n",
    "        'resnet_predictions': resnet_predictions,\n",
    "        'inception_predictions': inception_predictions,\n",
    "        'resnet_pred_classes': resnet_pred_classes,\n",
    "        'inception_pred_classes': inception_pred_classes,\n",
    "        'y_true': y_true,\n",
    "        'y_true_classes': y_true_classes\n",
    "    }\n",
    "\n",
    "# Evaluate models\n",
    "eval_results = evaluate_models(resnet_model, inception_model, test_ds, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84cca74",
   "metadata": {},
   "source": [
    "## 8. Results Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "740617ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'resnet_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 66\u001b[39m\n\u001b[32m     63\u001b[39m     plt.show()\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# Plot comparison\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m plot_training_comparison(\u001b[43mresnet_results\u001b[49m, inception_results)\n",
      "\u001b[31mNameError\u001b[39m: name 'resnet_results' is not defined"
     ]
    }
   ],
   "source": [
    "# Training history comparison\n",
    "def plot_training_comparison(resnet_results, inception_results):\n",
    "    # Combine histories\n",
    "    def combine_history(initial, finetune):\n",
    "        combined = {}\n",
    "        for key in initial.history.keys():\n",
    "            combined[key] = initial.history[key] + finetune.history[key]\n",
    "        return combined\n",
    "    \n",
    "    resnet_hist = combine_history(resnet_results['initial_history'], resnet_results['finetune_history'])\n",
    "    inception_hist = combine_history(inception_results['initial_history'], inception_results['finetune_history'])\n",
    "    \n",
    "    epochs = range(len(resnet_hist['accuracy']))\n",
    "    \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Accuracy\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(epochs, resnet_hist['accuracy'], 'b-', label='ResNet50 Train')\n",
    "    plt.plot(epochs, resnet_hist['val_accuracy'], 'b--', label='ResNet50 Val')\n",
    "    plt.plot(epochs, inception_hist['accuracy'], 'r-', label='InceptionV3 Train')\n",
    "    plt.plot(epochs, inception_hist['val_accuracy'], 'r--', label='InceptionV3 Val')\n",
    "    plt.title('Accuracy Comparison')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Loss\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(epochs, resnet_hist['loss'], 'b-', label='ResNet50 Train')\n",
    "    plt.plot(epochs, resnet_hist['val_loss'], 'b--', label='ResNet50 Val')\n",
    "    plt.plot(epochs, inception_hist['loss'], 'r-', label='InceptionV3 Train')\n",
    "    plt.plot(epochs, inception_hist['val_loss'], 'r--', label='InceptionV3 Val')\n",
    "    plt.title('Loss Comparison')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Final metrics comparison\n",
    "    plt.subplot(1, 3, 3)\n",
    "    metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "    resnet_final = [resnet_hist['val_accuracy'][-1], resnet_hist['val_precision'][-1], \n",
    "                    resnet_hist['val_recall'][-1], resnet_hist['val_f1_score'][-1]]\n",
    "    inception_final = [inception_hist['val_accuracy'][-1], inception_hist['val_precision'][-1], \n",
    "                       inception_hist['val_recall'][-1], inception_hist['val_f1_score'][-1]]\n",
    "    \n",
    "    x = np.arange(len(metrics))\n",
    "    width = 0.35\n",
    "    \n",
    "    plt.bar(x - width/2, resnet_final, width, label='ResNet50', alpha=0.8)\n",
    "    plt.bar(x + width/2, inception_final, width, label='InceptionV3', alpha=0.8)\n",
    "    \n",
    "    plt.title('Final Validation Metrics')\n",
    "    plt.xlabel('Metrics')\n",
    "    plt.ylabel('Score')\n",
    "    plt.xticks(x, metrics)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot comparison\n",
    "plot_training_comparison(resnet_results, inception_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4ae08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def plot_confusion_matrices(eval_results, class_names):\n",
    "    # Calculate confusion matrices\n",
    "    resnet_cm = confusion_matrix(eval_results['y_true_classes'], eval_results['resnet_pred_classes'])\n",
    "    inception_cm = confusion_matrix(eval_results['y_true_classes'], eval_results['inception_pred_classes'])\n",
    "    \n",
    "    # Normalize\n",
    "    resnet_cm_norm = resnet_cm.astype('float') / resnet_cm.sum(axis=1)[:, np.newaxis]\n",
    "    inception_cm_norm = inception_cm.astype('float') / inception_cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # ResNet50\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.heatmap(resnet_cm_norm, annot=True, fmt='.2f', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('ResNet50 - Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    \n",
    "    # InceptionV3\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.heatmap(inception_cm_norm, annot=True, fmt='.2f', cmap='Reds',\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('InceptionV3 - Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot confusion matrices\n",
    "plot_confusion_matrices(eval_results, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5bcd32",
   "metadata": {},
   "source": [
    "## 9. Final Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97774e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final comparison summary\n",
    "def generate_final_summary(eval_results):\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FINAL MODEL COMPARISON\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    resnet_metrics = eval_results['resnet_metrics']\n",
    "    inception_metrics = eval_results['inception_metrics']\n",
    "    \n",
    "    print(\"\\nTest Set Performance:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"{'Metric':<15} {'ResNet50':<12} {'InceptionV3':<12} {'Winner'}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    metrics_to_compare = ['accuracy', 'precision', 'recall', 'f1_score']\n",
    "    resnet_wins = 0\n",
    "    inception_wins = 0\n",
    "    \n",
    "    for metric in metrics_to_compare:\n",
    "        if metric in resnet_metrics and metric in inception_metrics:\n",
    "            resnet_val = resnet_metrics[metric]\n",
    "            inception_val = inception_metrics[metric]\n",
    "            \n",
    "            if resnet_val > inception_val:\n",
    "                winner = \"ResNet50\"\n",
    "                resnet_wins += 1\n",
    "            elif inception_val > resnet_val:\n",
    "                winner = \"InceptionV3\"\n",
    "                inception_wins += 1\n",
    "            else:\n",
    "                winner = \"Tie\"\n",
    "            \n",
    "            print(f\"{metric.capitalize():<15} {resnet_val:.4f}      {inception_val:.4f}      {winner}\")\n",
    "    \n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Overall Winner: {'ResNet50' if resnet_wins > inception_wins else 'InceptionV3' if inception_wins > resnet_wins else 'Tie'}\")\n",
    "    print(f\"Score: ResNet50: {resnet_wins}, InceptionV3: {inception_wins}\")\n",
    "    \n",
    "    # Model characteristics\n",
    "    print(\"\\nModel Characteristics:\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"ResNet50 parameters: {resnet_model.count_params():,}\")\n",
    "    print(f\"InceptionV3 parameters: {inception_model.count_params():,}\")\n",
    "    \n",
    "    return {\n",
    "        'resnet_metrics': resnet_metrics,\n",
    "        'inception_metrics': inception_metrics,\n",
    "        'resnet_wins': resnet_wins,\n",
    "        'inception_wins': inception_wins\n",
    "    }\n",
    "\n",
    "# Generate final summary\n",
    "final_summary = generate_final_summary(eval_results)\n",
    "\n",
    "print(\"\\n‚úÖ Model comparison completed!\")\n",
    "print(f\"üìÅ Models saved in: {PROJECT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862e9b8b",
   "metadata": {},
   "source": [
    "## 10. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023b2f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all results for future use\n",
    "def save_results():\n",
    "    results_dir = os.path.join(PROJECT_DIR, 'results')\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    print(\"Saving results...\")\n",
    "    \n",
    "    # Save models\n",
    "    resnet_model.save(os.path.join(results_dir, f\"resnet50_{timestamp}.keras\"))\n",
    "    inception_model.save(os.path.join(results_dir, f\"inceptionv3_{timestamp}.keras\"))\n",
    "    \n",
    "    # Save evaluation results\n",
    "    with open(os.path.join(results_dir, f\"eval_results_{timestamp}.pkl\"), 'wb') as f:\n",
    "        pickle.dump(eval_results, f)\n",
    "    \n",
    "    # Save summary\n",
    "    summary_data = {\n",
    "        'timestamp': timestamp,\n",
    "        'final_summary': {k: (v.tolist() if isinstance(v, np.ndarray) else float(v) if isinstance(v, (np.float32, np.float64)) else v) for k, v in final_summary.items()},\n",
    "        'class_names': class_names,\n",
    "        'class_weights': {str(k): float(v) for k, v in class_weights.items()}\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(results_dir, f\"summary_{timestamp}.json\"), 'w') as f:\n",
    "        json.dump(summary_data, f, indent=2)\n",
    "    \n",
    "    print(f\"‚úÖ Results saved with timestamp: {timestamp}\")\n",
    "    return timestamp\n",
    "\n",
    "# Save results\n",
    "save_timestamp = save_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ddfa8c",
   "metadata": {},
   "source": [
    "## 11. Load Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bd756d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load previously saved results\n",
    "def load_results(timestamp=None):\n",
    "    results_dir = os.path.join(PROJECT_DIR, 'results')\n",
    "    \n",
    "    if timestamp is None:\n",
    "        # Find latest timestamp\n",
    "        files = [f for f in os.listdir(results_dir) if f.startswith('summary_')]\n",
    "        if not files:\n",
    "            print(\"No saved results found\")\n",
    "            return False\n",
    "        timestamp = max([f.split('_')[1].split('.')[0] for f in files])\n",
    "    \n",
    "    print(f\"Loading results from: {timestamp}\")\n",
    "    \n",
    "    try:\n",
    "        # Load models\n",
    "        global resnet_model, inception_model, eval_results, final_summary\n",
    "        \n",
    "        resnet_model = keras.models.load_model(os.path.join(results_dir, f\"resnet50_{timestamp}.keras\"))\n",
    "        inception_model = keras.models.load_model(os.path.join(results_dir, f\"inceptionv3_{timestamp}.keras\"))\n",
    "        \n",
    "        # Load evaluation results\n",
    "        with open(os.path.join(results_dir, f\"eval_results_{timestamp}.pkl\"), 'rb') as f:\n",
    "            eval_results = pickle.load(f)\n",
    "        \n",
    "        # Load summary\n",
    "        with open(os.path.join(results_dir, f\"summary_{timestamp}.json\"), 'r') as f:\n",
    "            data = json.load(f)\n",
    "            final_summary = data['final_summary']\n",
    "        \n",
    "        print(\"‚úÖ Results loaded successfully!\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading results: {e}\")\n",
    "        return False\n",
    "\n",
    "# Quick load function\n",
    "# load_results()  # Uncomment to load latest results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee5b75a",
   "metadata": {},
   "source": [
    "## 12. Gradio Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad279df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install and import Gradio\n",
    "try:\n",
    "    import gradio as gr\n",
    "    import plotly.graph_objects as go\n",
    "except ImportError:\n",
    "    import subprocess\n",
    "    import sys\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"gradio\", \"plotly\"])\n",
    "    import gradio as gr\n",
    "    import plotly.graph_objects as go\n",
    "\n",
    "from PIL import Image, ImageEnhance\n",
    "import cv2\n",
    "\n",
    "print(\"Gradio interface ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d7aa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradio helper functions\n",
    "def preprocess_for_model(image, model_type='resnet50'):\n",
    "    if isinstance(image, Image.Image):\n",
    "        image = np.array(image)\n",
    "    \n",
    "    if len(image.shape) == 3 and image.shape[2] == 4:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGBA2RGB)\n",
    "    elif len(image.shape) == 2:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    image = cv2.resize(image, IMG_SIZE)\n",
    "    image = image.astype(np.float32)\n",
    "    \n",
    "    if image.max() <= 1.0:\n",
    "        image = image * 255.0\n",
    "    \n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    \n",
    "    if model_type == 'resnet50':\n",
    "        image = resnet_preprocess(image)\n",
    "    else:\n",
    "        image = inception_preprocess(image)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def create_confidence_plot(predictions, model_name):\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=class_names,\n",
    "        y=predictions * 100,\n",
    "        text=[f'{p:.1f}%' for p in predictions * 100],\n",
    "        textposition='auto'\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=f'{model_name} Confidence Scores',\n",
    "        xaxis_title='Disease Class',\n",
    "        yaxis_title='Confidence (%)',\n",
    "        yaxis=dict(range=[0, 100]),\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def predict_disease(image):\n",
    "    if image is None:\n",
    "        return \"Please upload an image\", None, None, None\n",
    "    \n",
    "    try:\n",
    "        # Preprocess for both models\n",
    "        resnet_img = preprocess_for_model(image, 'resnet50')\n",
    "        inception_img = preprocess_for_model(image, 'inceptionv3')\n",
    "        \n",
    "        # Predictions\n",
    "        resnet_pred = resnet_model.predict(resnet_img, verbose=0)[0]\n",
    "        inception_pred = inception_model.predict(inception_img, verbose=0)[0]\n",
    "        \n",
    "        # Top predictions\n",
    "        resnet_top = np.argmax(resnet_pred)\n",
    "        inception_top = np.argmax(inception_pred)\n",
    "        \n",
    "        # Format results\n",
    "        results = f\"\"\"\n",
    "## ResNet50 Prediction\n",
    "**Primary:** {class_names[resnet_top]} ({resnet_pred[resnet_top]*100:.1f}%)\n",
    "\n",
    "## InceptionV3 Prediction  \n",
    "**Primary:** {class_names[inception_top]} ({inception_pred[inception_top]*100:.1f}%)\n",
    "\n",
    "## Model Agreement\n",
    "{'‚úÖ Both models agree' if resnet_top == inception_top else '‚ö†Ô∏è Models disagree'}\n",
    "\"\"\"\n",
    "        \n",
    "        # Create plots\n",
    "        resnet_plot = create_confidence_plot(resnet_pred, \"ResNet50\")\n",
    "        inception_plot = create_confidence_plot(inception_pred, \"InceptionV3\")\n",
    "        \n",
    "        # Summary table\n",
    "        summary_df = pd.DataFrame({\n",
    "            'Model': ['ResNet50', 'InceptionV3'],\n",
    "            'Prediction': [class_names[resnet_top], class_names[inception_top]],\n",
    "            'Confidence': [f'{resnet_pred[resnet_top]*100:.1f}%', f'{inception_pred[inception_top]*100:.1f}%']\n",
    "        })\n",
    "        \n",
    "        return results, resnet_plot, inception_plot, summary_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\", None, None, None\n",
    "\n",
    "print(\"Prediction functions ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c44d674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Gradio interface\n",
    "def create_interface():\n",
    "    with gr.Blocks(title=\"OCTDL Eye Disease Classification\", theme=gr.themes.Soft()) as interface:\n",
    "        \n",
    "        gr.HTML(\"\"\"\n",
    "        <div style=\"text-align: center; padding: 2rem; background: linear-gradient(90deg, #667eea 0%, #764ba2 100%); color: white; border-radius: 10px;\">\n",
    "            <h1>üè• OCTDL Eye Disease Classification</h1>\n",
    "            <h3>ResNet50 vs InceptionV3 Model Comparison</h3>\n",
    "            <p>Advanced Machine Learning Final Project | June 2025</p>\n",
    "        </div>\n",
    "        \"\"\")\n",
    "        \n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                gr.Markdown(\"### Upload OCT Image\")\n",
    "                image_input = gr.Image(type=\"pil\", label=\"OCT Image\", height=300)\n",
    "                predict_btn = gr.Button(\"üîç Analyze Image\", variant=\"primary\", size=\"lg\")\n",
    "                \n",
    "                gr.Markdown(\"\"\"\n",
    "                **Supported:** JPG, PNG, TIFF  \n",
    "                **Classes:** AMD, DME, ERM, NO, RAO, RVO, VID  \n",
    "                **Note:** For research purposes only\n",
    "                \"\"\")\n",
    "        \n",
    "        gr.Markdown(\"## üìä Analysis Results\")\n",
    "        \n",
    "        results_text = gr.Markdown(value=\"Upload an image to see predictions\")\n",
    "        \n",
    "        with gr.Row():\n",
    "            summary_table = gr.Dataframe(\n",
    "                headers=[\"Model\", \"Prediction\", \"Confidence\"],\n",
    "                label=\"Summary\"\n",
    "            )\n",
    "        \n",
    "        with gr.Row():\n",
    "            resnet_plot = gr.Plot(label=\"ResNet50 Confidence\")\n",
    "            inception_plot = gr.Plot(label=\"InceptionV3 Confidence\")\n",
    "        \n",
    "        # Connect events\n",
    "        predict_btn.click(\n",
    "            fn=predict_disease,\n",
    "            inputs=[image_input],\n",
    "            outputs=[results_text, resnet_plot, inception_plot, summary_table]\n",
    "        )\n",
    "        \n",
    "        image_input.change(\n",
    "            fn=predict_disease,\n",
    "            inputs=[image_input],\n",
    "            outputs=[results_text, resnet_plot, inception_plot, summary_table]\n",
    "        )\n",
    "        \n",
    "        gr.HTML(\"\"\"\n",
    "        <div style=\"text-align: center; padding: 1rem; margin-top: 2rem; border-top: 1px solid #ddd; color: #666;\">\n",
    "            <p><strong>‚ö†Ô∏è Disclaimer:</strong> For research purposes only - Not for clinical diagnosis</p>\n",
    "        </div>\n",
    "        \"\"\")\n",
    "    \n",
    "    return interface\n",
    "\n",
    "# Create interface\n",
    "if 'resnet_model' in globals() and 'inception_model' in globals():\n",
    "    gradio_interface = create_interface()\n",
    "    print(\"‚úÖ Gradio interface created!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Models not loaded. Run training or load_results() first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247f1377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch Gradio interface\n",
    "def launch_interface():\n",
    "    if 'gradio_interface' not in globals():\n",
    "        print(\"‚ùå Interface not created. Run the previous cell first.\")\n",
    "        return\n",
    "    \n",
    "    print(\"üöÄ Launching interface...\")\n",
    "    print(\"üåê Interface will open at: http://localhost:7860\")\n",
    "    \n",
    "    gradio_interface.launch(\n",
    "        server_name=\"127.0.0.1\",\n",
    "        server_port=7860,\n",
    "        share=False,\n",
    "        inbrowser=True,\n",
    "        quiet=False\n",
    "    )\n",
    "\n",
    "# Instructions\n",
    "print(\"üéØ Ready to launch!\")\n",
    "print(\"Run: launch_interface()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496000ca",
   "metadata": {},
   "source": [
    "---\n",
    "**Project Complete** ‚úÖ  \n",
    "All models trained, evaluated, and ready for deployment via Gradio interface."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
